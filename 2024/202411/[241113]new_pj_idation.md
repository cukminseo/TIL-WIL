## TIL

### 어떤 데이터를 노이즈로 볼 것인가? 에 대한 사고

#### 필요성

- LLM은 기존에 학습된 데이터가 충분히 있기 때문에, 우리 데이터셋의 paragraph의 부족 등을 노이즈로 선택하고 제거하는 것은 효용성이 낮을 수 있음.
- 또한 test set에서도 비슷한 노이즈가 있을경우(eg. 밑줄친~ ; paragraph에 밑줄이 있을 수 없음) train set에서 제거할경우 성능하락의 여지가 있음.
- 따라서 어떤 데이터를 노이즈로 볼 것인가를 고민해봐야함.
  - 연역적으로 생각해본 고성능모델 활용 디노이즈 방향성을 제시함.

#### 방향성

- 수능 최적화된 LLM모델 만들기
  - 모델에게 paragraph+question+answer을 추가학습시키기
- 디노이즈를 하는 이유: 모델이 학습할 필요가 없거나, 학습을 해도 의미없는 데이터를 없애는 것
- 어떤 데이터를 노이즈로 판단할 것인가?
  - 특정 문제는 paragraph가 빈약하더라도 Q-A쌍만 맞다면 우리 base모델의 기존 지식으로 풀 수 있지않을까?
- 만약 우리 모델이 학습데이터를 추가학습시키지않고 **바로 학습데이터를 inferance시켰을 때 올바른 대답을 할 수 있다면?**
  - 해당 데이터는 모델이 이미 충분히 학습한 내용이므로, **추가 학습을 통해 얻을 수 있는 이점이 크지 않음**
  - 하지만 현재 Task의 **형식과 구조를 학습할 수 있다는 점에서 굳이 제거할 필요도 없음**
- **우리 모델이 학습없이 못 푸는 문제를 고성능 모델(eg. GPT-4o)이 풀 수 있다면?**
  - 이 경우 데이터의 **Q-A쌍에서는 적어도 문제가 없다는 말** 이므로, 학습시킬 경우 성능 향상을 기대할 수 있음
  - 단, 고성능 모델의 기본지식으로 문제를 풀었을 수도 있으므로 **paragraph에 노이즈가 있는가?에 대해서는 별도로 확인** 해야 함
  - 이 경우 해당 고성능 모델을 통한 **paragraph 증강을 통한 방법을 고려** 해볼 수 있을 것 같음
- **우리 모델이 학습없이 못 푸는 문제를 고성능 모델(eg. GPT-4o)이 풀 수 없다면?**
  - 기존에 모델이 해당 지식을 가지고 있어서 해당 지식으로 풀었을 경우; **Q-A쌍에서 문제가 있을 가능성이 있음**
  - 기존에 모델이 해당 지식을 가지고 있지 않았을 경우; **paragraph에 문제가 있을 수 있음**
  - 해당 모델의 기학습 지식으로도 Q-A를 못풀었으므로, 해당 **고성능모델을 통해 paragraph를 증강하여도 성능향상의 기대가 낮음**

- Q-A에서의 오류는 삭제하고, paragraph의 부족은 그자체로 노이즈증강으로 보거나 GPT에게 추가 생성을 맡기면 좋은 데이터가 되지 않을까?

- 이를 통해 모든 데이터를 확인하는 것보다 단계적으로 문제가 될만한 데이터를 추려나가며 확인해보면 좋을 것 같다.

- GPT 4o, GPT 3.5 turbo, GPT 4o mini를 통한 train data 추론 

## Retrospect
